{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485b8da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGA shape: (2256, 25)\n",
      "Tunnel shape: (1198, 25)\n",
      "Columns:\n",
      " ['flow_id', 'src_ip', 'dst_ip', 'src_port', 'dst_port', 'protocol', 'n_sent', 'sent_bytes', 'sent_pkt_min', 'sent_pkt_mean', 'sent_pkt_max', 'sent_iat_min', 'sent_iat_mean', 'sent_iat_max', 'n_recv', 'recv_bytes', 'recv_pkt_min', 'recv_pkt_mean', 'recv_pkt_max', 'recv_iat_min', 'recv_iat_mean', 'recv_iat_max', 'server_delay', 'bytes_ratio', 'label']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# File paths\n",
    "dga_file = \"/home/ubuntu/DoH_DGA_training/datasets/DGA/all_pcaps.csv\"\n",
    "tunnel_file = \"/home/ubuntu/DoH_DGA_training/datasets/DoH_HKD/DoH-Pcaps/DoH-Pcaps-dnstt/dnstt_all_pcaps.csv\"\n",
    "\n",
    "# Load datasets\n",
    "df_dga = pd.read_csv(dga_file)\n",
    "df_tunnel = pd.read_csv(tunnel_file)\n",
    "\n",
    "# Assign labels\n",
    "df_dga[\"label\"] = \"DGA\"\n",
    "df_tunnel[\"label\"] = \"tunnel\"\n",
    "\n",
    "print(\"DGA shape:\", df_dga.shape)\n",
    "print(\"Tunnel shape:\", df_tunnel.shape)\n",
    "\n",
    "# Print columns to confirm structure\n",
    "print(\"Columns:\\n\", list(df_dga.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca3886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (3454, 25)\n",
      "label\n",
      "DGA       2256\n",
      "tunnel    1198\n",
      "Name: count, dtype: int64\n",
      "Features shape: (3454, 16)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate into one dataframe\n",
    "final_df = pd.concat([df_dga, df_tunnel], ignore_index=True)\n",
    "\n",
    "print(\"Final dataset shape:\", final_df.shape)\n",
    "print(final_df[\"label\"].value_counts())\n",
    "\n",
    "# Separate features and target\n",
    "y = final_df[\"label\"]\n",
    "X = final_df.drop(columns=[\"label\", 'flow_id', 'src_ip', 'dst_ip', 'src_port', 'dst_port', 'protocol', 'n_recv', 'n_sent'])\n",
    "\n",
    "# Keep only numeric features\n",
    "X = X.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6b287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2dafe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['DGA' 'tunnel']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# --- Assume you already have your dataset loaded as X, y ---\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "print(\"Classes:\", le.classes_)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc2c99",
   "metadata": {},
   "source": [
    "### MLP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad67138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean classification:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DGA       1.00      1.00      1.00       451\n",
      "      tunnel       0.99      1.00      1.00       240\n",
      "\n",
      "    accuracy                           1.00       691\n",
      "   macro avg       1.00      1.00      1.00       691\n",
      "weighted avg       1.00      1.00      1.00       691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Define MLP ---\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden1=128, hidden2=64, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(X_train.shape[1], num_classes=len(le.classes_))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- Train ---\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# --- Evaluate clean ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test).argmax(dim=1)\n",
    "    print(\"Clean classification:\\n\")\n",
    "    print(classification_report(y_test, preds, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8e1a7",
   "metadata": {},
   "source": [
    "### Adversarial FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f20380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FGSM Attack ---\n",
    "def fgsm_attack(model, x, y, epsilon, target_class=None):\n",
    "    x_adv = x.clone().detach().requires_grad_(True)\n",
    "    outputs = model(x_adv)\n",
    "\n",
    "    # Targeted: force DGA -> Tunnel\n",
    "    if target_class is not None:\n",
    "        y_target = torch.full_like(y, target_class)\n",
    "        loss = criterion(outputs, y_target)\n",
    "    else:\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    perturbation = epsilon * x_adv.grad.sign()\n",
    "    x_adv = x_adv + perturbation\n",
    "    return torch.clamp(x_adv, -5, 5).detach()  # keep in a valid range\n",
    "\n",
    "# Get only DGA samples from test set\n",
    "dga_label = np.where(le.classes_ == \"DGA\")[0][0]\n",
    "dga_idx = (y_test == dga_label).nonzero().squeeze()\n",
    "X_dga = X_test[dga_idx]\n",
    "y_dga = y_test[dga_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1adb32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untargeted FGSM flip rate (DGA misclassified): 12.20%\n"
     ]
    }
   ],
   "source": [
    "# Get label indices\n",
    "dga_label = le.transform([\"DGA\"])[0]\n",
    "tunnel_label = le.transform([\"tunnel\"])[0]\n",
    "\n",
    "# Extract only DGA samples\n",
    "dga_idx = (y_test == dga_label).nonzero().squeeze()\n",
    "X_dga = X_test[dga_idx]\n",
    "y_dga = y_test[dga_idx]\n",
    "\n",
    "# Untargeted attack first\n",
    "X_dga_adv = fgsm_attack(model, X_dga, y_dga, epsilon=0.2, target_class=None)\n",
    "\n",
    "adv_preds = model(X_dga_adv).argmax(dim=1)\n",
    "\n",
    "flip_rate = (adv_preds != y_dga).float().mean().item()\n",
    "print(f\"Untargeted FGSM flip rate (DGA misclassified): {flip_rate:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff7d3b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon=0.1: Targeted success 0.00%\n",
      "Epsilon=0.2: Targeted success 0.00%\n",
      "Epsilon=0.5: Targeted success 0.00%\n",
      "Epsilon=1.0: Targeted success 0.00%\n"
     ]
    }
   ],
   "source": [
    "for eps in [0.1, 0.2, 0.5, 1.0]:\n",
    "    X_dga_adv = fgsm_attack(model, X_dga, y_dga, epsilon=eps, target_class=tunnel_label)\n",
    "    adv_preds = model(X_dga_adv).argmax(dim=1)\n",
    "    success_rate = (adv_preds == tunnel_label).float().mean().item()\n",
    "    print(f\"Epsilon={eps}: Targeted success {success_rate:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822590a",
   "metadata": {},
   "source": [
    "### PGD instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5350a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, x, y, epsilon, alpha, iters, target_class=None):\n",
    "    x_adv = x.clone().detach()\n",
    "    for i in range(iters):\n",
    "        x_adv.requires_grad_(True)\n",
    "        outputs = model(x_adv)\n",
    "        if target_class is not None:\n",
    "            y_target = torch.full_like(y, target_class)\n",
    "            loss = criterion(outputs, y_target)\n",
    "        else:\n",
    "            loss = criterion(outputs, y)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            grad = x_adv.grad.sign()\n",
    "            if target_class is not None:\n",
    "                x_adv = x_adv - alpha * grad  # targeted → descend\n",
    "            else:\n",
    "                x_adv = x_adv + alpha * grad  # untargeted → ascend\n",
    "            # Project into epsilon-ball\n",
    "            perturb = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
    "            x_adv = torch.clamp(x + perturb, -5, 5)\n",
    "    return x_adv.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4f6b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD targeted success: 0.9312638640403748\n"
     ]
    }
   ],
   "source": [
    "X_dga_adv = pgd_attack(model, X_dga, y_dga, epsilon=0.5, alpha=0.05, iters=40, target_class=tunnel_label)\n",
    "adv_preds = model(X_dga_adv).argmax(dim=1)\n",
    "success_rate = (adv_preds == tunnel_label).float().mean().item()\n",
    "print(\"PGD targeted success:\", success_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3a1cf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    orig_f0        adv_f0  orig_f1     adv_f1     orig_f2     adv_f2  orig_f3  \\\n",
      "0  208933.0  157772.78125     52.0  49.693684  102.922661  53.293518    646.0   \n",
      "1  208933.0  157772.78125     52.0  49.693684  102.922661  53.293518    646.0   \n",
      "2  209973.0  158812.78125     52.0  49.693684  102.425850  52.796715    646.0   \n",
      "3  209037.0  157876.78125     52.0  49.693684  102.872536  53.243397    646.0   \n",
      "4  208992.0  157831.78125     52.0  49.693684  102.901031  53.271896    646.0   \n",
      "\n",
      "       adv_f3       orig_f4    adv_f4  ...   adv_f11  orig_f12   adv_f12  \\\n",
      "0  494.442169  9.536689e-07 -0.002086  ...  0.029968  0.025965 -2.339527   \n",
      "1  494.442169  1.907343e-06 -0.002085  ...  0.029965  0.026937 -2.338555   \n",
      "2  494.442169  1.907343e-06 -0.002085  ...  0.029965  0.027250 -2.338242   \n",
      "3  494.442169  1.907343e-06 -0.002085  ...  0.029969  0.025561 -2.339931   \n",
      "4  494.442169  2.145776e-06 -0.002084  ...  0.029965  0.021380 -2.344112   \n",
      "\n",
      "    orig_f13      adv_f13  orig_f14   adv_f14  orig_f15   adv_f15  \\\n",
      "0  10.114022 -2838.795410  0.000071  0.002009  0.642572  1.366493   \n",
      "1  10.117990 -2838.791504  0.000067  0.002005  0.642616  1.366536   \n",
      "2  10.098886 -2838.810547  0.000071  0.002009  0.643302  1.367222   \n",
      "3  10.118539 -2838.791016  0.000066  0.002004  0.642584  1.366504   \n",
      "4  10.092721 -2838.816650  0.000074  0.002012  0.642274  1.366194   \n",
      "\n",
      "   adv_prediction  \n",
      "0          tunnel  \n",
      "1          tunnel  \n",
      "2          tunnel  \n",
      "3          tunnel  \n",
      "4          tunnel  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Saved adversarial samples to pgd_adversarial_success.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# --- 1. Generate PGD adversarial samples ---\n",
    "X_dga_adv = pgd_attack(\n",
    "    model, \n",
    "    X_dga, \n",
    "    y_dga, \n",
    "    epsilon=0.5, \n",
    "    alpha=0.05, \n",
    "    iters=40, \n",
    "    target_class=tunnel_label\n",
    ")\n",
    "\n",
    "# --- 2. Predictions on adversarial samples ---\n",
    "adv_preds = model(X_dga_adv).argmax(dim=1)\n",
    "\n",
    "# Convert to numpy for easier handling\n",
    "X_dga_adv_np = X_dga_adv.detach().cpu().numpy()\n",
    "adv_preds_np = adv_preds.detach().cpu().numpy()\n",
    "y_dga_np = y_dga.detach().cpu().numpy()\n",
    "\n",
    "# --- 3. Inverse transform to original feature scale ---\n",
    "X_dga_adv_original = scaler.inverse_transform(X_dga_adv_np)\n",
    "X_dga_original = scaler.inverse_transform(X_dga.detach().cpu().numpy())\n",
    "\n",
    "# --- 4. Filter: only those that succeeded (predicted tunnel) ---\n",
    "success_idx = np.where(adv_preds_np == tunnel_label)[0]\n",
    "\n",
    "X_adv_success = X_dga_adv_original[success_idx]\n",
    "X_orig_success = X_dga_original[success_idx]\n",
    "\n",
    "# --- 5. Build a DataFrame with original vs adversarial ---\n",
    "df_success = pd.DataFrame()\n",
    "\n",
    "for i in range(X.shape[1]):  # for each feature\n",
    "    df_success[f\"orig_f{i}\"] = X_orig_success[:, i]\n",
    "    df_success[f\"adv_f{i}\"] = X_adv_success[:, i]\n",
    "\n",
    "df_success[\"adv_prediction\"] = le.inverse_transform(adv_preds_np[success_idx])\n",
    "\n",
    "# --- 6. Print first few ---\n",
    "print(df_success.head())\n",
    "\n",
    "# --- 7. Save to CSV ---\n",
    "df_success.to_csv(\"pgd_adversarial_success.csv\", index=False)\n",
    "print(\"Saved adversarial samples to pgd_adversarial_success.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045171fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
