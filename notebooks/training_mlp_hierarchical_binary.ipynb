{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9adbbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGA shape: (406808, 35)\n",
      "DoH_Tunnel shape: (707228, 35)\n",
      "NonDoH_Benign shape: (2139204, 36)\n",
      "DoH_Benign shape: (116412, 36)\n",
      "\n",
      "Final dataset shape: (3369652, 36)\n",
      "Labels distribution:\n",
      " label\n",
      "NonDoH_Benign    2139204\n",
      "DoH_Tunnel        707228\n",
      "DGA               406808\n",
      "DoH_Benign        116412\n",
      "Name: count, dtype: int64\n",
      "Columns (sample): ['session_id', 'client_ip', 'server_ip', 'client_port', 'server_port', 'protocol', 'N', 'n_client', 'client_bytes', 'client_pkt_min', 'client_pkt_mean', 'client_pkt_max', 'client_iat_min', 'client_iat_mean', 'client_iat_max', 'n_server', 'server_bytes', 'server_pkt_min', 'server_pkt_mean', 'server_pkt_max', 'server_iat_min', 'server_iat_mean', 'server_iat_max', 'pkt_fraction_client', 'bytes_fraction_client', 'flow_duration', 'time_first_response', 'dir_switches', 'size_min', 'size_mean', 'size_max', 'iat_min', 'iat_mean', 'iat_max', 'label', 'source_pcap']\n",
      "\n",
      "\n",
      "======== Running pipeline for N = 8 ========\n",
      "Dataset size for N=8: 842413\n",
      "\n",
      "Stage A_NonDoH_vs_DoH+DGA (N=8) - samples: 842413, numeric features used: 16\n",
      "Label distribution: Counter({'NonDoH': 534801, 'DoH_or_DGA': 307612})\n",
      "Training MLP for A_NonDoH_vs_DoH+DGA (N=8)...\n",
      "\n",
      "Classification report for Stage=A_NonDoH_vs_DoH+DGA, N=8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  DoH_or_DGA     0.9972    0.9984    0.9978     61523\n",
      "      NonDoH     0.9991    0.9984    0.9987    106960\n",
      "\n",
      "    accuracy                         0.9984    168483\n",
      "   macro avg     0.9981    0.9984    0.9983    168483\n",
      "weighted avg     0.9984    0.9984    0.9984    168483\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 61423    100]\n",
      " [   173 106787]]\n",
      "\n",
      "Stage B_DoHBenign_vs_DGA+Tunnel (N=8) - samples: 307612, numeric features used: 16\n",
      "Label distribution: Counter({'DGA_or_Tunnel': 278509, 'DoH_Benign': 29103})\n",
      "Training MLP for B_DoHBenign_vs_DGA+Tunnel (N=8)...\n",
      "\n",
      "Classification report for Stage=B_DoHBenign_vs_DGA+Tunnel, N=8:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "DGA_or_Tunnel     0.9999    0.9999    0.9999     55702\n",
      "   DoH_Benign     0.9991    0.9995    0.9993      5821\n",
      "\n",
      "     accuracy                         0.9999     61523\n",
      "    macro avg     0.9995    0.9997    0.9996     61523\n",
      " weighted avg     0.9999    0.9999    0.9999     61523\n",
      "\n",
      "Confusion matrix:\n",
      " [[55697     5]\n",
      " [    3  5818]]\n",
      "\n",
      "Stage C_DGA_vs_Tunnel (N=8) - samples: 278509, numeric features used: 16\n",
      "Label distribution: Counter({'DoH_Tunnel': 176807, 'DGA': 101702})\n",
      "Training MLP for C_DGA_vs_Tunnel (N=8)...\n",
      "\n",
      "Classification report for Stage=C_DGA_vs_Tunnel, N=8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DGA     0.9999    1.0000    0.9999     20340\n",
      "  DoH_Tunnel     1.0000    0.9999    1.0000     35362\n",
      "\n",
      "    accuracy                         0.9999     55702\n",
      "   macro avg     0.9999    1.0000    0.9999     55702\n",
      "weighted avg     0.9999    0.9999    0.9999     55702\n",
      "\n",
      "Confusion matrix:\n",
      " [[20340     0]\n",
      " [    3 35359]]\n",
      "\n",
      "\n",
      "======== Running pipeline for N = 16 ========\n",
      "Dataset size for N=16: 842413\n",
      "\n",
      "Stage A_NonDoH_vs_DoH+DGA (N=16) - samples: 842413, numeric features used: 16\n",
      "Label distribution: Counter({'NonDoH': 534801, 'DoH_or_DGA': 307612})\n",
      "Training MLP for A_NonDoH_vs_DoH+DGA (N=16)...\n",
      "\n",
      "Classification report for Stage=A_NonDoH_vs_DoH+DGA, N=16:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  DoH_or_DGA     0.9962    0.9982    0.9972     61523\n",
      "      NonDoH     0.9989    0.9978    0.9984    106960\n",
      "\n",
      "    accuracy                         0.9979    168483\n",
      "   macro avg     0.9976    0.9980    0.9978    168483\n",
      "weighted avg     0.9979    0.9979    0.9979    168483\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 61410    113]\n",
      " [   236 106724]]\n",
      "\n",
      "Stage B_DoHBenign_vs_DGA+Tunnel (N=16) - samples: 307612, numeric features used: 16\n",
      "Label distribution: Counter({'DGA_or_Tunnel': 278509, 'DoH_Benign': 29103})\n",
      "Training MLP for B_DoHBenign_vs_DGA+Tunnel (N=16)...\n",
      "\n",
      "Classification report for Stage=B_DoHBenign_vs_DGA+Tunnel, N=16:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "DGA_or_Tunnel     1.0000    0.9999    1.0000     55702\n",
      "   DoH_Benign     0.9995    0.9998    0.9997      5821\n",
      "\n",
      "     accuracy                         0.9999     61523\n",
      "    macro avg     0.9997    0.9999    0.9998     61523\n",
      " weighted avg     0.9999    0.9999    0.9999     61523\n",
      "\n",
      "Confusion matrix:\n",
      " [[55699     3]\n",
      " [    1  5820]]\n",
      "\n",
      "Stage C_DGA_vs_Tunnel (N=16) - samples: 278509, numeric features used: 16\n",
      "Label distribution: Counter({'DoH_Tunnel': 176807, 'DGA': 101702})\n",
      "Training MLP for C_DGA_vs_Tunnel (N=16)...\n",
      "\n",
      "Classification report for Stage=C_DGA_vs_Tunnel, N=16:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DGA     0.9998    1.0000    0.9999     20340\n",
      "  DoH_Tunnel     1.0000    0.9999    0.9999     35362\n",
      "\n",
      "    accuracy                         0.9999     55702\n",
      "   macro avg     0.9999    0.9999    0.9999     55702\n",
      "weighted avg     0.9999    0.9999    0.9999     55702\n",
      "\n",
      "Confusion matrix:\n",
      " [[20340     0]\n",
      " [    4 35358]]\n",
      "\n",
      "\n",
      "======== Running pipeline for N = 32 ========\n",
      "Dataset size for N=32: 842413\n",
      "\n",
      "Stage A_NonDoH_vs_DoH+DGA (N=32) - samples: 842413, numeric features used: 16\n",
      "Label distribution: Counter({'NonDoH': 534801, 'DoH_or_DGA': 307612})\n",
      "Training MLP for A_NonDoH_vs_DoH+DGA (N=32)...\n",
      "\n",
      "Classification report for Stage=A_NonDoH_vs_DoH+DGA, N=32:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  DoH_or_DGA     0.9967    0.9984    0.9976     61523\n",
      "      NonDoH     0.9991    0.9981    0.9986    106960\n",
      "\n",
      "    accuracy                         0.9982    168483\n",
      "   macro avg     0.9979    0.9983    0.9981    168483\n",
      "weighted avg     0.9982    0.9982    0.9982    168483\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 61425     98]\n",
      " [   203 106757]]\n",
      "\n",
      "Stage B_DoHBenign_vs_DGA+Tunnel (N=32) - samples: 307612, numeric features used: 16\n",
      "Label distribution: Counter({'DGA_or_Tunnel': 278509, 'DoH_Benign': 29103})\n",
      "Training MLP for B_DoHBenign_vs_DGA+Tunnel (N=32)...\n",
      "\n",
      "Classification report for Stage=B_DoHBenign_vs_DGA+Tunnel, N=32:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "DGA_or_Tunnel     0.9999    0.9999    0.9999     55702\n",
      "   DoH_Benign     0.9995    0.9995    0.9995      5821\n",
      "\n",
      "     accuracy                         0.9999     61523\n",
      "    macro avg     0.9997    0.9997    0.9997     61523\n",
      " weighted avg     0.9999    0.9999    0.9999     61523\n",
      "\n",
      "Confusion matrix:\n",
      " [[55699     3]\n",
      " [    3  5818]]\n",
      "\n",
      "Stage C_DGA_vs_Tunnel (N=32) - samples: 278509, numeric features used: 16\n",
      "Label distribution: Counter({'DoH_Tunnel': 176807, 'DGA': 101702})\n",
      "Training MLP for C_DGA_vs_Tunnel (N=32)...\n",
      "\n",
      "Classification report for Stage=C_DGA_vs_Tunnel, N=32:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DGA     0.9999    1.0000    0.9999     20340\n",
      "  DoH_Tunnel     1.0000    0.9999    1.0000     35362\n",
      "\n",
      "    accuracy                         0.9999     55702\n",
      "   macro avg     0.9999    1.0000    0.9999     55702\n",
      "weighted avg     0.9999    0.9999    0.9999     55702\n",
      "\n",
      "Confusion matrix:\n",
      " [[20340     0]\n",
      " [    3 35359]]\n",
      "\n",
      "\n",
      "======== Running pipeline for N = 64 ========\n",
      "Dataset size for N=64: 842413\n",
      "\n",
      "Stage A_NonDoH_vs_DoH+DGA (N=64) - samples: 842413, numeric features used: 16\n",
      "Label distribution: Counter({'NonDoH': 534801, 'DoH_or_DGA': 307612})\n",
      "Training MLP for A_NonDoH_vs_DoH+DGA (N=64)...\n",
      "\n",
      "Classification report for Stage=A_NonDoH_vs_DoH+DGA, N=64:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  DoH_or_DGA     0.9973    0.9987    0.9980     61523\n",
      "      NonDoH     0.9992    0.9984    0.9988    106960\n",
      "\n",
      "    accuracy                         0.9985    168483\n",
      "   macro avg     0.9982    0.9985    0.9984    168483\n",
      "weighted avg     0.9985    0.9985    0.9985    168483\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 61440     83]\n",
      " [   168 106792]]\n",
      "\n",
      "Stage B_DoHBenign_vs_DGA+Tunnel (N=64) - samples: 307612, numeric features used: 16\n",
      "Label distribution: Counter({'DGA_or_Tunnel': 278509, 'DoH_Benign': 29103})\n",
      "Training MLP for B_DoHBenign_vs_DGA+Tunnel (N=64)...\n",
      "\n",
      "Classification report for Stage=B_DoHBenign_vs_DGA+Tunnel, N=64:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "DGA_or_Tunnel     0.9999    0.9999    0.9999     55702\n",
      "   DoH_Benign     0.9993    0.9988    0.9991      5821\n",
      "\n",
      "     accuracy                         0.9998     61523\n",
      "    macro avg     0.9996    0.9994    0.9995     61523\n",
      " weighted avg     0.9998    0.9998    0.9998     61523\n",
      "\n",
      "Confusion matrix:\n",
      " [[55698     4]\n",
      " [    7  5814]]\n",
      "\n",
      "Stage C_DGA_vs_Tunnel (N=64) - samples: 278509, numeric features used: 16\n",
      "Label distribution: Counter({'DoH_Tunnel': 176807, 'DGA': 101702})\n",
      "Training MLP for C_DGA_vs_Tunnel (N=64)...\n",
      "\n",
      "Classification report for Stage=C_DGA_vs_Tunnel, N=64:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DGA     1.0000    1.0000    1.0000     20340\n",
      "  DoH_Tunnel     1.0000    1.0000    1.0000     35362\n",
      "\n",
      "    accuracy                         1.0000     55702\n",
      "   macro avg     1.0000    1.0000    1.0000     55702\n",
      "weighted avg     1.0000    1.0000    1.0000     55702\n",
      "\n",
      "Confusion matrix:\n",
      " [[20340     0]\n",
      " [    1 35361]]\n",
      "\n",
      "\n",
      "Summary results (first rows):\n",
      "   N                      stage          class  precision    recall        f1  \\\n",
      "0  8        A_NonDoH_vs_DoH+DGA     DoH_or_DGA   0.997191  0.998375  0.997783   \n",
      "1  8        A_NonDoH_vs_DoH+DGA         NonDoH   0.999064  0.998383  0.998723   \n",
      "2  8  B_DoHBenign_vs_DGA+Tunnel  DGA_or_Tunnel   0.999946  0.999910  0.999928   \n",
      "3  8  B_DoHBenign_vs_DGA+Tunnel     DoH_Benign   0.999141  0.999485  0.999313   \n",
      "4  8            C_DGA_vs_Tunnel            DGA   0.999853  1.000000  0.999926   \n",
      "5  8            C_DGA_vs_Tunnel     DoH_Tunnel   1.000000  0.999915  0.999958   \n",
      "\n",
      "    support  \n",
      "0   61523.0  \n",
      "1  106960.0  \n",
      "2   55702.0  \n",
      "3    5821.0  \n",
      "4   20340.0  \n",
      "5   35362.0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ---- Config ----\n",
    "N_values = [8, 16, 32, 64]      # run for each N\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "# MLP config (example - match what you used earlier)\n",
    "mlp_params = dict(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,\n",
    "    batch_size=64,\n",
    "    learning_rate=\"adaptive\",\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=500,\n",
    "    shuffle=True,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=20,\n",
    "    random_state=random_state,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# File paths\n",
    "# ===============================\n",
    "doh_tunnel_iodine = \"/home/ubuntu/DoH_DGA_training/datasets/PCAPs/DoHMalicious/iodine/all_pcaps_allN.csv\"\n",
    "doh_tunnel_dns2tcp = \"/home/ubuntu/DoH_DGA_training/datasets/PCAPs/DoHMalicious/dns2tcp/all_pcaps_allN.csv\"\n",
    "doh_tunnel_dnscat2 = \"/home/ubuntu/DoH_DGA_training/datasets/PCAPs/DoHMalicious/dnscat2/all_pcaps_allN.csv\"\n",
    "\n",
    "dga_malware_google = \"/home/ubuntu/DoH_DGA_training/datasets/DGA_Google/all_pcaps_allN.csv\"\n",
    "dga_malware_clouflare = \"/home/ubuntu/DoH_DGA_training/datasets/DGA_CF/all_pcaps_allN.csv\"\n",
    "dga_malware_adguard = \"/home/ubuntu/DoH_DGA_training/datasets/DGA_ADGuard/all_pcaps_allN.csv\"\n",
    "dga_malware_quad9 = \"/home/ubuntu/DoH_DGA_training/datasets/DGA_Quad9/all_pcaps_allN.csv\"\n",
    "\n",
    "nondoh_benign_file = \"/home/ubuntu/DoH_DGA_training/datasets/PCAPs/DoHBenign-NonDoH/all_nondoh.csv\"\n",
    "doh_benign_file = \"/home/ubuntu/DoH_DGA_training/datasets/PCAPs/DoHBenign-NonDoH/all_doh.csv\"\n",
    "\n",
    "# ===============================\n",
    "# Load datasets\n",
    "# ===============================\n",
    "df_doh_tunnel_iodine = pd.read_csv(doh_tunnel_iodine)\n",
    "df_doh_tunnel_dns2tcp = pd.read_csv(doh_tunnel_dns2tcp)\n",
    "df_doh_tunnel_dnscat2 = pd.read_csv(doh_tunnel_dnscat2)\n",
    "df_doh_tunnel = pd.concat([df_doh_tunnel_iodine, df_doh_tunnel_dns2tcp, df_doh_tunnel_dnscat2], ignore_index=True)\n",
    "\n",
    "df_dga_google = pd.read_csv(dga_malware_google)\n",
    "df_dga_clouflare = pd.read_csv(dga_malware_clouflare)\n",
    "df_dga_adguard = pd.read_csv(dga_malware_adguard)\n",
    "df_dga_quad9 = pd.read_csv(dga_malware_quad9)\n",
    "df_dga = pd.concat([df_dga_google, df_dga_clouflare, df_dga_adguard, df_dga_quad9], ignore_index=True)\n",
    "\n",
    "df_nondoh_benign = pd.read_csv(nondoh_benign_file)\n",
    "df_doh_benign = pd.read_csv(doh_benign_file)\n",
    "\n",
    "# ===============================\n",
    "# Assign labels (consistent)\n",
    "# ===============================\n",
    "df_dga[\"label\"] = \"DGA\"\n",
    "df_doh_tunnel[\"label\"] = \"DoH_Tunnel\"\n",
    "df_nondoh_benign[\"label\"] = \"NonDoH_Benign\"\n",
    "df_doh_benign[\"label\"] = \"DoH_Benign\"\n",
    "\n",
    "# ===============================\n",
    "# Combine all into one DataFrame (note: removed duplicate doh_benign)\n",
    "# ===============================\n",
    "df_all = pd.concat([df_dga, df_doh_tunnel, df_nondoh_benign, df_doh_benign], ignore_index=True)\n",
    "\n",
    "print(\"DGA shape:\", df_dga.shape)\n",
    "print(\"DoH_Tunnel shape:\", df_doh_tunnel.shape)\n",
    "print(\"NonDoH_Benign shape:\", df_nondoh_benign.shape)\n",
    "print(\"DoH_Benign shape:\", df_doh_benign.shape)\n",
    "print(\"\\nFinal dataset shape:\", df_all.shape)\n",
    "print(\"Labels distribution:\\n\", df_all[\"label\"].value_counts())\n",
    "print(\"Columns (sample):\", list(df_all.columns)[:40])\n",
    "\n",
    "# ===============================\n",
    "# Keep only the desired columns in df_all (features + label + N if present)\n",
    "# ===============================\n",
    "FEATURE_COLS = [\n",
    "    'client_pkt_max', 'server_bytes', 'n_server', 'client_bytes', 'size_max',\n",
    "    'n_client', 'server_pkt_max', 'pkt_fraction_client', 'bytes_fraction_client',\n",
    "    'dir_switches', 'size_mean', 'client_pkt_mean', 'size_min',\n",
    "    'client_pkt_min', 'server_pkt_min', 'server_pkt_mean'\n",
    "]\n",
    "# ---------- Updated stage definition functions (pipeline style) ----------\n",
    "def make_stage_A(df):\n",
    "    \"\"\"Stage A: NonDoH vs (DGA, DoH_Benign, DoH_Tunnel)\"\"\"\n",
    "    df_stage = df.copy()\n",
    "    df_stage = df_stage[df_stage[\"label\"].isin([\"NonDoH_Benign\", \"DGA\", \"DoH_Benign\", \"DoH_Tunnel\"])].copy()\n",
    "    # NonDoH_Benign stays NonDoH; everything else grouped as DoH_or_DGA\n",
    "    df_stage[\"stage_label\"] = df_stage[\"label\"].apply(lambda x: \"NonDoH\" if str(x) == \"NonDoH_Benign\" else \"DoH_or_DGA\")\n",
    "    return df_stage\n",
    "\n",
    "def make_stage_B(df):\n",
    "    \"\"\"Stage B: (input should be the output of A filtered to DoH_or_DGA)\n",
    "       DoH_Benign vs (DGA, DoH_Tunnel) -> labels are 'DoH_Benign' and 'DGA_or_Tunnel'\"\"\"\n",
    "    df_stage = df.copy()\n",
    "    # keep only relevant raw labels\n",
    "    df_stage = df_stage[df_stage[\"label\"].isin([\"DGA\", \"DoH_Benign\", \"DoH_Tunnel\"])].copy()\n",
    "    df_stage[\"stage_label\"] = df_stage[\"label\"].apply(lambda x: \"DoH_Benign\" if str(x) == \"DoH_Benign\" else \"DGA_or_Tunnel\")\n",
    "    return df_stage\n",
    "\n",
    "def make_stage_C(df):\n",
    "    \"\"\"Stage C: (input should be the output of B filtered to DGA_or_Tunnel)\n",
    "       DGA vs DoH_Tunnel\"\"\"\n",
    "    df_stage = df.copy()\n",
    "    df_stage = df_stage[df_stage[\"label\"].isin([\"DGA\", \"DoH_Tunnel\"])].copy()\n",
    "    df_stage[\"stage_label\"] = df_stage[\"label\"].apply(lambda x: \"DGA\" if str(x).startswith(\"DGA\") else \"DoH_Tunnel\")\n",
    "    return df_stage\n",
    "\n",
    "# ---------- helper to run one stage (train/eval/record metrics) ----------\n",
    "results = []\n",
    "\n",
    "def run_stage(df_stage, stage_name, N):\n",
    "    \"\"\"Train & evaluate stage using df_stage which must already contain 'stage_label'.\"\"\"\n",
    "    if df_stage is None or df_stage.shape[0] == 0:\n",
    "        print(f\"Stage {stage_name} (N={N}): no data, skipping\")\n",
    "        return\n",
    "\n",
    "    df_stage = df_stage.dropna(subset=[\"stage_label\"]).copy()\n",
    "    if df_stage.shape[0] == 0:\n",
    "        print(f\"Stage {stage_name} (N={N}): all rows had null stage_label, skipping\")\n",
    "        return\n",
    "\n",
    "    y = df_stage[\"stage_label\"].copy()\n",
    "\n",
    "    # select only the feature columns we keep (safe intersection)\n",
    "    available = [c for c in FEATURE_COLS if c in df_stage.columns]\n",
    "    missing = [c for c in FEATURE_COLS if c not in df_stage.columns]\n",
    "    if missing:\n",
    "        print(f\"Warning: missing feature columns for Stage={stage_name}, N={N}: {missing}\")\n",
    "\n",
    "    X = df_stage[available].copy()\n",
    "    X = X.drop(columns=[\"label\", \"stage_label\"], errors=\"ignore\")\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    if X.shape[1] == 0:\n",
    "        print(f\"Stage {stage_name} (N={N}): no numeric features available after selection, skipping.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nStage {stage_name} (N={N}) - samples: {X.shape[0]}, numeric features used: {X.shape[1]}\")\n",
    "    print(\"Label distribution:\", Counter(y))\n",
    "\n",
    "    # ensure we have at least two classes\n",
    "    if len(y.unique()) < 2:\n",
    "        print(f\"Stage {stage_name} (N={N}) has <2 classes, skipping.\")\n",
    "        return\n",
    "\n",
    "    # encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # guard for stratify requirements\n",
    "    min_samples_needed = int(np.ceil(1.0 / test_size))\n",
    "    counts = Counter(y_enc)\n",
    "    if any(v < 2 for v in counts.values()) or any(v < min_samples_needed for v in counts.values()):\n",
    "        print(\"Warning: not enough samples for stratified split; using non-stratified split.\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_enc, test_size=test_size, random_state=random_state, shuffle=True\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y_enc, test_size=test_size, stratify=y_enc, random_state=random_state\n",
    "        )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"mlp\", MLPClassifier(**mlp_params))\n",
    "    ])\n",
    "\n",
    "    print(f\"Training MLP for {stage_name} (N={N})...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(f\"\\nClassification report for Stage={stage_name}, N={N}:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_, digits=4))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # store summary metrics\n",
    "    report_dict = classification_report(y_test, y_pred, target_names=le.classes_, output_dict=True)\n",
    "    for cls in le.classes_:\n",
    "        entry = {\n",
    "            \"N\": N,\n",
    "            \"stage\": stage_name,\n",
    "            \"class\": cls,\n",
    "            \"precision\": report_dict[cls][\"precision\"],\n",
    "            \"recall\": report_dict[cls][\"recall\"],\n",
    "            \"f1\": report_dict[cls][\"f1-score\"],\n",
    "            \"support\": report_dict[cls][\"support\"]\n",
    "        }\n",
    "        results.append(entry)\n",
    "\n",
    "# ---------- Main loop (pipeline order: A -> B -> C) ----------\n",
    "for N in N_values:\n",
    "    print(f\"\\n\\n======== Running pipeline for N = {N} ========\")\n",
    "\n",
    "    # filter by N if available\n",
    "    if \"N\" in df_all.columns:\n",
    "        df_subset = df_all[df_all[\"N\"] == N].copy()\n",
    "        print(f\"Dataset size for N={N}: {df_subset.shape[0]}\")\n",
    "        if df_subset.shape[0] == 0:\n",
    "            print(\"No rows for this N, skipping.\")\n",
    "            continue\n",
    "    else:\n",
    "        print(\"Column 'N' not found in df_all â€” using entire dataset (no per-N filtering).\")\n",
    "        df_subset = df_all.copy()\n",
    "\n",
    "    # ---------- Stage A ----------\n",
    "    df_A = make_stage_A(df_subset)\n",
    "    run_stage(df_A, \"A_NonDoH_vs_DoH+DGA\", N)\n",
    "\n",
    "    # For Stage B, pipeline uses only the \"DoH_or_DGA\" group from Stage A\n",
    "    df_for_B = df_A[df_A[\"stage_label\"] == \"DoH_or_DGA\"].copy()\n",
    "    if df_for_B.shape[0] == 0:\n",
    "        print(f\"Stage B (N={N}): no samples passed from Stage A -> skipping Stage B and C.\")\n",
    "        continue\n",
    "\n",
    "    # map into Stage B labels and run\n",
    "    df_B = make_stage_B(df_for_B)\n",
    "    run_stage(df_B, \"B_DoHBenign_vs_DGA+Tunnel\", N)\n",
    "\n",
    "    # For Stage C, pipeline uses only the \"DGA_or_Tunnel\" group from Stage B\n",
    "    df_for_C = df_B[df_B[\"stage_label\"] == \"DGA_or_Tunnel\"].copy()\n",
    "    if df_for_C.shape[0] == 0:\n",
    "        print(f\"Stage C (N={N}): no samples passed from Stage B -> skipping Stage C.\")\n",
    "        continue\n",
    "\n",
    "    df_C = make_stage_C(df_for_C)\n",
    "    run_stage(df_C, \"C_DGA_vs_Tunnel\", N)\n",
    "\n",
    "# ---- collect results to DataFrame ----\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\\nSummary results (first rows):\")\n",
    "print(results_df.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112461c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
